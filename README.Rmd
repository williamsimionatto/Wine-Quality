---
title: "Red Wine Quality"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 
library(ggplot2)
```

Este projeto tem por objetivo treinar um modelo do machine learning para prever a qualidade do vinho vermelho. Para este treinamento será utilizado o modelo `Árvore de decisão`, por meio do pacote (`C50`).

## Dataset

```{r echo=FALSE}
WineData <- read.table("winequality-red.csv", sep=",", header=TRUE)
WineData$quality <- as.factor(WineData$quality)
```

O Dataset está disponível em: [Red Wine Quality](https://www.kaggle.com/datasets/uciml/red-wine-quality-cortez-et-al-2009).

O Dataset apresenta os dados de `r nrow(WineData)` vinhos, distribuídos entre `r ncol(WineData)` variáveis coletadas com base em testes físicos-químicos:

1.  `fixed acidity`

  * Representa a volatilidade dos ácidos presentes no vinho, ou seja, ácidos que não evaporam facilmente.

2.  `volatile acidity`

  * Representa a quantidade de ácido acético no vinho, ou seja, níveis muito altos podem causar um sabador de vinagre no vinho.

3.  `citric acid`

  * Representa a quantidade de ácido cítrico presente no vinho.

4.  `residual sugar`

  * Representa a quantidade de açúcar restante no vinho após o processo de fermentação.

5. `chlorides`

  * Representa a quantidade de sal presente no vinho.

6.  `free sulfur dioxide`

  * Representa a quantidade de gás SO2 liberado.

7.  `total sulfur dioxide`

  * Representa o total de gás SO2.

8. `density`

  * Representa a densidade do vinho.

9.  `pH`

  * Representa quão ácido ou básico é um vinho em uma escala de 0 (muito ácido) a 14 (muito básico);

10. `sulphates`

  * Um aditivo de vinho que pode contribuir para os níveis de dióxido de enxofre

11. `alcohol`

  * Representa a percentagem de teor alcoólico do vinho.

12 . `quality`

  * Representa a pontuação do vinho, em uma escala de 0 a 10. Sendo 0 um vinho considerado `ruim` e 10 um vinho `bom`.


## Análise Exploratória dos dados

Uma breve análise dos dados, para poder entender suas características. 

```{r echo=FALSE}
WineData <- read.table("winequality-red.csv", sep=",", header=TRUE)

ggplot(WineData, aes(x = quality)) +
  geom_histogram(binwidth = 1, fill = 'chartreuse',  col=I("chartreuse4")) +
  scale_x_continuous(breaks = seq(3, 8, by = 1)) +
  ggtitle("Distribuição da Qualidade") +
  xlab("Qualidade") +
  ylab("Total")
```

Como podemos ver pelo gráfico da `Distribuição da Qualidade`, a qualidade do vinho predomina entre `5` e `6`.

```{r echo=FALSE}
WineData$quality <- as.factor(WineData$quality)

ggplot(WineData, aes(x = density, y = alcohol, color = quality)) +
  geom_point(alpha=0.1) +
  geom_smooth(se = FALSE, size=0.8) +
  ggtitle('Densidade por teor alcoolico do vinho') +
  labs(y = 'Teor Alcoolico', x = 'Densidade', color = 'Qualidade do Vinho')
```

A partir do gráfico gerado, podemos observar que a tendência geral é que quanto maior o teor álcoolico do vinho, menor a sua densidade. Nesta análise, pode-se concluir também que quanto maior a qualidade do vinho, maior o teor alcoólico e menor a densidade.

```{r echo=FALSE}
ggplot(WineData, aes(x = residual.sugar, color = quality)) +
  geom_density() +
  scale_color_brewer(type = 'seq', palette = 'RdPu') +
  scale_x_log10(breaks = seq(1, 15, 2)) +
  scale_y_continuous(breaks = seq(0, 1.5, .25)) +
  labs(x = 'Açúcar Residual por Litro', y = 'Densidade', color = 'Qualidade do Vinho') +
  ggtitle('Densidade por açúcar residual em escala log segmentado por qualidade')

```

Vemos que a densidade por açúcar residual tem uma distribuição bimodal para os vinhos de maior qualidade e uma cauda longa para os de menor qualidade mas de forma pouco significativa.


```{r echo=FALSE}
ggplot(WineData, aes(x = pH)) +
  geom_histogram(binwidth = .1, fill = 'chartreuse',  col=I("chartreuse4")) +
  ggtitle("Distribuição pH") +
  xlab("pH") +
  ylab("Count")
```

O pH presentes nos vinhos, apresenta uma distribuição normal e bem concentrada, na faixa entre `3.0` e `3.7`.

## Preparação dos dados para aplicação do modelo
Para preparação dos dados, foi necessário criar uma variável categorica para a qualidade do vinho, aplicando o seguinte critério:

```{r echo=FALSE}
WineData <- read.table("winequality-red.csv", sep=",", header=TRUE)
WineData$quality <- ifelse(WineData$quality < 5, 'ruim', ifelse(WineData$quality > 6, 'bom', 'normal'))
WineData$quality <- as.factor(WineData$quality)
data_distributiation =  prop.table(table(WineData$quality))
```

> Qualidade < 5 = ruim,
> Qualidade > 5 & Qualidade < 6 = normal,
> Qualidade > 6 = boa

Com isso os dados ficaram distribuidos da seguinte forma:
```{r echo=FALSE}
  knitr::kable(data_distributiation, caption = "Distribuição dos dados originais")
```

Os dados foram separados aleatoriamente entre dados de 'test' e 'training', onde 80% dos dados foram separados para testes e os 20% restantes separados para treinamento do modelo.

```{r echo=FALSE}

set.seed(123)
train_sample <- sample(nrow(WineData), 0.8 * nrow(WineData))
WineData_train <- WineData[train_sample, ]
WineData_test <- WineData[-train_sample, ]

training_distributiation =  prop.table(table(WineData_train$quality))
test_distributiation = prop.table(table(WineData_test$quality))
```

Após a separação os dados ficaram distruibuidos da seguinte forma:
```{r echo=FALSE}
  knitr::kable(training_distributiation, caption = "Distribuição dos dados de treinamento")

  knitr::kable(test_distributiation, caption = "Distribuição dos dados de testes")
```

É possível notar que os dados não estão distribuídos de maneira uniforme, pois em ambos os datasets há uma maior concentração de vinhos considerados `normais`, cerca de 80%, porém segue a distribuição dos dados originais.

## Aplicação do Modelo

Utilizando os dados separados para treinamento e aplicando o modelo de classificação C5.0 e posteriormente fazendo a predição, utilizando a função `predict`, do modelo gerado após o treinamento e o dados separados para testes, gerou a seguinte matriz de confusão.

```{r echo=FALSE}
library(C50)
WineData_model <- C5.0(WineData_train[-12], WineData_train$quality)
WineData_predict <- predict(WineData_model, WineData_test)

library(caret)
confusionMatrix <- confusionMatrix(WineData_test$quality, WineData_predict)
confusionMatrixTable <- as.data.frame(confusionMatrix$table)
confusionMatrixTable$diag <- confusionMatrixTable$Prediction == confusionMatrixTable$Reference
confusionMatrixTable$ref_freq <- confusionMatrixTable$Freq * ifelse(is.na(confusionMatrixTable$diag),-1,1)
confusionMatrixStats <-data.frame(confusionMatrix$overall)

ggplot(data = confusionMatrixTable, aes(x = Prediction , y =  Reference, fill = Freq))+
  scale_x_discrete(position = "top") +
  geom_tile( data = confusionMatrixTable, aes(fill = ref_freq)) +
  scale_fill_gradient2(guide = FALSE, low="red3", high="orchid4", midpoint = 0, na.value = 'white') +
  geom_text(aes(label = Freq), color = 'black', size = 3) +
  theme_bw() +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        legend.position = "none",
        panel.border = element_blank(),
        plot.background = element_blank(),
        axis.line = element_blank(),
  )
```

Conforme a tabela abaixo é possível ver que o modelo teve uma precisão não tão alta, cerca de `85%`.

```{r echo=FALSE}
knitr::kable(confusionMatrixStats, caption = "Precisão do modelo")
```

### Utilizando mais árvores

Em tempo, foi aplicado o modelo com até 20 árvores de decisão, a fim de obter a melhor precisão. Dessa forma, obteve-se o seguinte gráfico: 

```{r echo=FALSE}
error.rate = NULL
trials <- 1:20

for(i in trials){
  set.seed(123)
  model = C5.0(WineData_train[-12], WineData_train$quality, trials = i)
  predict <- predict(model, WineData_test)
  error.rate[i] = mean(WineData_test$quality != predict)
}

error.df <- data.frame(error.rate,trials)

ggplot(error.df,aes(x=trials,y=error.rate)) +
  geom_point() + 
  geom_line(lty="dotted",color='red')
```

Observando, é possível perceber que o modelo não possui uma regularidade na execução, pois a precisão varia muito conforme o número de árvores, tendo a melhor precisão com 12 `árvores` com cerca de `96%` de precisão.
